{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3974a7a-9086-4af5-9c79-dcc3473b83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/emiz6413/training-gemma-2-9b-4-bit-qlora-fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee25494-d8d3-47c7-a106-6258ce9160a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.42.3 in /opt/conda/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.3)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.33.0)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (2024.7.24)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.42.3) (4.66.5)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.42.3) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.42.3) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.42.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.42.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.42.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.42.3) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# gemma-2 is available from transformers>=4.42.3\n",
    "!pip install -U \"transformers>=4.42.3\" bitsandbytes accelerate peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3526f1b-e977-45cc-a3fa-cd9fc3ef62ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a689244b-33f7-4633-89a3-766acec36718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450722dc-d252-411e-aea9-503f46cac371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    Gemma2ForSequenceClassification,\n",
    "    GemmaTokenizerFast,\n",
    "    Gemma2Config,\n",
    "    Qwen2TokenizerFast,\n",
    "    Qwen2ForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizerBase, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38c38af-ccd5-4ac4-9702-b31d0ee1beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = \"qwen2001\"\n",
    "    checkpoint: str = \"unsloth/Qwen2-72B-bnb-4bit\"  # 4-bit quantized llama-3.1-8b-instruct\n",
    "    max_length: int = 256\n",
    "    n_splits: int = 5\n",
    "    fold_idx: int = 0\n",
    "    optim_type: str = \"adamw_8bit\"\n",
    "    per_device_train_batch_size: int = 1\n",
    "    gradient_accumulation_steps: int = 4  # global batch size is 24\n",
    "    per_device_eval_batch_size: int = 24\n",
    "    n_epochs: int = 1\n",
    "    freeze_layers: int = 16  # there're 42 layers in total, we don't add adapters to the first 16 layers\n",
    "    lr: float = 2e-4\n",
    "    warmup_steps: int = 20\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: float = lora_r * 2\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = \"none\"\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae1da73-b464-4449-9b85-6216c922d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=config.output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    optim=config.optim_type,\n",
    "    fp16=True,\n",
    "    learning_rate=config.lr,\n",
    "    warmup_steps=config.warmup_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963bb9e0-25a8-4ca2-96ab-8ea35369ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    # only target self-attention\n",
    "    #target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    target_modules=['k_proj','up_proj','gate_proj','q_proj','base_layer','o_proj','v_proj','down_proj'],\n",
    "    #target_modules=[\"q_proj\", \"k_proj\", 'v_proj','o_proj','gate_proj'],\n",
    "    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b3c7189-db55-4f21-a9f5-7269193285e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Qwen2TokenizerFast.from_pretrained(config.checkpoint)#モデルによって変える\n",
    "tokenizer.add_eos_token = True  # We'll add <eos> at the end\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "766465a9-a667-4c0b-9007-573ac71fe5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea40051163c47d3a1342d7446c37325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at unsloth/Qwen2-72B-bnb-4bit and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForSequenceClassification(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(152064, 8192, padding_idx=151646)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2SdpaAttention(\n",
       "              (q_proj): Linear4bit(in_features=8192, out_features=8192, bias=True)\n",
       "              (k_proj): Linear4bit(in_features=8192, out_features=1024, bias=True)\n",
       "              (v_proj): Linear4bit(in_features=8192, out_features=1024, bias=True)\n",
       "              (o_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)\n",
       "              (rotary_emb): Qwen2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear4bit(in_features=8192, out_features=29568, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=8192, out_features=29568, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=29568, out_features=8192, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((8192,), eps=1e-05)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((8192,), eps=1e-05)\n",
       "          )\n",
       "          (16-41): 26 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2SdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=8192, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): Qwen2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=29568, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=29568, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=29568, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=29568, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=29568, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=29568, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((8192,), eps=1e-05)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((8192,), eps=1e-05)\n",
       "          )\n",
       "          (42-79): 38 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2SdpaAttention(\n",
       "              (q_proj): Linear4bit(in_features=8192, out_features=8192, bias=True)\n",
       "              (k_proj): Linear4bit(in_features=8192, out_features=1024, bias=True)\n",
       "              (v_proj): Linear4bit(in_features=8192, out_features=1024, bias=True)\n",
       "              (o_proj): Linear4bit(in_features=8192, out_features=8192, bias=False)\n",
       "              (rotary_emb): Qwen2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): Linear4bit(in_features=8192, out_features=29568, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=8192, out_features=29568, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=29568, out_features=8192, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((8192,), eps=1e-05)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((8192,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((8192,), eps=1e-05)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=8192, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=8192, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Qwen2ForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=2,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bdd3841-3e7e-4b67-ae8f-dd9d2d6fb7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gate_proj',\n",
       " 'down_proj',\n",
       " 'up_proj',\n",
       " 'k_proj',\n",
       " 'v_proj',\n",
       " 'o_proj',\n",
       " 'base_layer',\n",
       " 'q_proj']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit  # (default:torch.nn.Linear,4bit:bnb.nn.Linear4bit,8bit:bnb.nn.Linear8bitLt)\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names: # needed for 16-bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "find_all_linear_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7442f63d-8fee-47cc-96df-73227b18d516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.0.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.0.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.0.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight\n",
      "base_model.model.model.layers.0.input_layernorm.weight\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.1.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.1.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.1.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight\n",
      "base_model.model.model.layers.1.input_layernorm.weight\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.2.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.2.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.2.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight\n",
      "base_model.model.model.layers.2.input_layernorm.weight\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.3.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.3.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.3.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight\n",
      "base_model.model.model.layers.3.input_layernorm.weight\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.4.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.4.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.4.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight\n",
      "base_model.model.model.layers.4.input_layernorm.weight\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.5.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.5.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.5.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight\n",
      "base_model.model.model.layers.5.input_layernorm.weight\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.6.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.6.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.6.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight\n",
      "base_model.model.model.layers.6.input_layernorm.weight\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.7.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.7.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.7.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight\n",
      "base_model.model.model.layers.7.input_layernorm.weight\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.8.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.8.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.8.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight\n",
      "base_model.model.model.layers.8.input_layernorm.weight\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.9.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.9.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.9.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight\n",
      "base_model.model.model.layers.9.input_layernorm.weight\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.10.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.10.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.10.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight\n",
      "base_model.model.model.layers.10.input_layernorm.weight\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.11.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.11.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.11.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight\n",
      "base_model.model.model.layers.11.input_layernorm.weight\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.12.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.12.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.12.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight\n",
      "base_model.model.model.layers.12.input_layernorm.weight\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.13.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.13.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.13.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight\n",
      "base_model.model.model.layers.13.input_layernorm.weight\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.14.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.14.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.14.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight\n",
      "base_model.model.model.layers.14.input_layernorm.weight\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.15.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.15.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.15.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight\n",
      "base_model.model.model.layers.15.input_layernorm.weight\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.16.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.input_layernorm.weight\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.17.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.input_layernorm.weight\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.18.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.input_layernorm.weight\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.19.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.input_layernorm.weight\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.20.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.input_layernorm.weight\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.21.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.input_layernorm.weight\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.22.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.input_layernorm.weight\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.23.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.input_layernorm.weight\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.24.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.input_layernorm.weight\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.25.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.input_layernorm.weight\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.26.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.input_layernorm.weight\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.27.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.input_layernorm.weight\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.28.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.input_layernorm.weight\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.29.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.input_layernorm.weight\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.30.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.input_layernorm.weight\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.31.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.input_layernorm.weight\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.32.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.32.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.32.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.32.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.32.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.32.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.32.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.32.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.32.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.32.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.32.input_layernorm.weight\n",
      "base_model.model.model.layers.32.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.33.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.33.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.33.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.33.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.33.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.33.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.33.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.33.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.33.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.33.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.33.input_layernorm.weight\n",
      "base_model.model.model.layers.33.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.34.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.34.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.34.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.34.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.34.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.34.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.34.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.34.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.34.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.34.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.34.input_layernorm.weight\n",
      "base_model.model.model.layers.34.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.35.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.35.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.35.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.35.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.35.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.35.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.35.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.35.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.35.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.35.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.35.input_layernorm.weight\n",
      "base_model.model.model.layers.35.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.36.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.36.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.36.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.36.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.36.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.36.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.36.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.36.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.36.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.36.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.36.input_layernorm.weight\n",
      "base_model.model.model.layers.36.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.37.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.37.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.37.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.37.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.37.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.37.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.37.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.37.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.37.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.37.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.37.input_layernorm.weight\n",
      "base_model.model.model.layers.37.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.38.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.38.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.38.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.38.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.38.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.38.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.38.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.38.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.38.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.38.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.38.input_layernorm.weight\n",
      "base_model.model.model.layers.38.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.39.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.39.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.39.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.39.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.39.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.39.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.39.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.39.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.39.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.39.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.39.input_layernorm.weight\n",
      "base_model.model.model.layers.39.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.40.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.40.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.40.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.40.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.40.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.40.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.40.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.40.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.40.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.40.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.40.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.40.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.40.input_layernorm.weight\n",
      "base_model.model.model.layers.40.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.41.self_attn.q_proj.base_layer.weight\n",
      "base_model.model.model.layers.41.self_attn.q_proj.base_layer.bias\n",
      "base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.41.self_attn.k_proj.base_layer.weight\n",
      "base_model.model.model.layers.41.self_attn.k_proj.base_layer.bias\n",
      "base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.41.self_attn.v_proj.base_layer.weight\n",
      "base_model.model.model.layers.41.self_attn.v_proj.base_layer.bias\n",
      "base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.41.self_attn.o_proj.base_layer.weight\n",
      "base_model.model.model.layers.41.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.41.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.41.mlp.gate_proj.base_layer.weight\n",
      "base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.41.mlp.up_proj.base_layer.weight\n",
      "base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.41.mlp.down_proj.base_layer.weight\n",
      "base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.41.input_layernorm.weight\n",
      "base_model.model.model.layers.41.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.42.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.42.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.42.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.42.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.42.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.42.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.42.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.42.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.42.mlp.up_proj.weight\n",
      "base_model.model.model.layers.42.mlp.down_proj.weight\n",
      "base_model.model.model.layers.42.input_layernorm.weight\n",
      "base_model.model.model.layers.42.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.43.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.43.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.43.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.43.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.43.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.43.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.43.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.43.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.43.mlp.up_proj.weight\n",
      "base_model.model.model.layers.43.mlp.down_proj.weight\n",
      "base_model.model.model.layers.43.input_layernorm.weight\n",
      "base_model.model.model.layers.43.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.44.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.44.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.44.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.44.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.44.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.44.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.44.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.44.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.44.mlp.up_proj.weight\n",
      "base_model.model.model.layers.44.mlp.down_proj.weight\n",
      "base_model.model.model.layers.44.input_layernorm.weight\n",
      "base_model.model.model.layers.44.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.45.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.45.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.45.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.45.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.45.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.45.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.45.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.45.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.45.mlp.up_proj.weight\n",
      "base_model.model.model.layers.45.mlp.down_proj.weight\n",
      "base_model.model.model.layers.45.input_layernorm.weight\n",
      "base_model.model.model.layers.45.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.46.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.46.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.46.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.46.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.46.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.46.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.46.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.46.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.46.mlp.up_proj.weight\n",
      "base_model.model.model.layers.46.mlp.down_proj.weight\n",
      "base_model.model.model.layers.46.input_layernorm.weight\n",
      "base_model.model.model.layers.46.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.47.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.47.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.47.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.47.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.47.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.47.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.47.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.47.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.47.mlp.up_proj.weight\n",
      "base_model.model.model.layers.47.mlp.down_proj.weight\n",
      "base_model.model.model.layers.47.input_layernorm.weight\n",
      "base_model.model.model.layers.47.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.48.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.48.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.48.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.48.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.48.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.48.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.48.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.48.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.48.mlp.up_proj.weight\n",
      "base_model.model.model.layers.48.mlp.down_proj.weight\n",
      "base_model.model.model.layers.48.input_layernorm.weight\n",
      "base_model.model.model.layers.48.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.49.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.49.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.49.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.49.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.49.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.49.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.49.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.49.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.49.mlp.up_proj.weight\n",
      "base_model.model.model.layers.49.mlp.down_proj.weight\n",
      "base_model.model.model.layers.49.input_layernorm.weight\n",
      "base_model.model.model.layers.49.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.50.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.50.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.50.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.50.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.50.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.50.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.50.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.50.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.50.mlp.up_proj.weight\n",
      "base_model.model.model.layers.50.mlp.down_proj.weight\n",
      "base_model.model.model.layers.50.input_layernorm.weight\n",
      "base_model.model.model.layers.50.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.51.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.51.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.51.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.51.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.51.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.51.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.51.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.51.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.51.mlp.up_proj.weight\n",
      "base_model.model.model.layers.51.mlp.down_proj.weight\n",
      "base_model.model.model.layers.51.input_layernorm.weight\n",
      "base_model.model.model.layers.51.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.52.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.52.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.52.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.52.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.52.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.52.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.52.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.52.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.52.mlp.up_proj.weight\n",
      "base_model.model.model.layers.52.mlp.down_proj.weight\n",
      "base_model.model.model.layers.52.input_layernorm.weight\n",
      "base_model.model.model.layers.52.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.53.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.53.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.53.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.53.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.53.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.53.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.53.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.53.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.53.mlp.up_proj.weight\n",
      "base_model.model.model.layers.53.mlp.down_proj.weight\n",
      "base_model.model.model.layers.53.input_layernorm.weight\n",
      "base_model.model.model.layers.53.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.54.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.54.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.54.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.54.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.54.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.54.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.54.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.54.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.54.mlp.up_proj.weight\n",
      "base_model.model.model.layers.54.mlp.down_proj.weight\n",
      "base_model.model.model.layers.54.input_layernorm.weight\n",
      "base_model.model.model.layers.54.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.55.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.55.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.55.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.55.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.55.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.55.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.55.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.55.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.55.mlp.up_proj.weight\n",
      "base_model.model.model.layers.55.mlp.down_proj.weight\n",
      "base_model.model.model.layers.55.input_layernorm.weight\n",
      "base_model.model.model.layers.55.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.56.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.56.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.56.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.56.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.56.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.56.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.56.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.56.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.56.mlp.up_proj.weight\n",
      "base_model.model.model.layers.56.mlp.down_proj.weight\n",
      "base_model.model.model.layers.56.input_layernorm.weight\n",
      "base_model.model.model.layers.56.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.57.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.57.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.57.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.57.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.57.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.57.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.57.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.57.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.57.mlp.up_proj.weight\n",
      "base_model.model.model.layers.57.mlp.down_proj.weight\n",
      "base_model.model.model.layers.57.input_layernorm.weight\n",
      "base_model.model.model.layers.57.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.58.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.58.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.58.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.58.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.58.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.58.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.58.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.58.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.58.mlp.up_proj.weight\n",
      "base_model.model.model.layers.58.mlp.down_proj.weight\n",
      "base_model.model.model.layers.58.input_layernorm.weight\n",
      "base_model.model.model.layers.58.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.59.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.59.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.59.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.59.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.59.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.59.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.59.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.59.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.59.mlp.up_proj.weight\n",
      "base_model.model.model.layers.59.mlp.down_proj.weight\n",
      "base_model.model.model.layers.59.input_layernorm.weight\n",
      "base_model.model.model.layers.59.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.60.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.60.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.60.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.60.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.60.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.60.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.60.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.60.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.60.mlp.up_proj.weight\n",
      "base_model.model.model.layers.60.mlp.down_proj.weight\n",
      "base_model.model.model.layers.60.input_layernorm.weight\n",
      "base_model.model.model.layers.60.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.61.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.61.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.61.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.61.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.61.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.61.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.61.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.61.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.61.mlp.up_proj.weight\n",
      "base_model.model.model.layers.61.mlp.down_proj.weight\n",
      "base_model.model.model.layers.61.input_layernorm.weight\n",
      "base_model.model.model.layers.61.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.62.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.62.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.62.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.62.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.62.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.62.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.62.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.62.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.62.mlp.up_proj.weight\n",
      "base_model.model.model.layers.62.mlp.down_proj.weight\n",
      "base_model.model.model.layers.62.input_layernorm.weight\n",
      "base_model.model.model.layers.62.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.63.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.63.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.63.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.63.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.63.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.63.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.63.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.63.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.63.mlp.up_proj.weight\n",
      "base_model.model.model.layers.63.mlp.down_proj.weight\n",
      "base_model.model.model.layers.63.input_layernorm.weight\n",
      "base_model.model.model.layers.63.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.64.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.64.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.64.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.64.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.64.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.64.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.64.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.64.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.64.mlp.up_proj.weight\n",
      "base_model.model.model.layers.64.mlp.down_proj.weight\n",
      "base_model.model.model.layers.64.input_layernorm.weight\n",
      "base_model.model.model.layers.64.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.65.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.65.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.65.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.65.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.65.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.65.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.65.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.65.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.65.mlp.up_proj.weight\n",
      "base_model.model.model.layers.65.mlp.down_proj.weight\n",
      "base_model.model.model.layers.65.input_layernorm.weight\n",
      "base_model.model.model.layers.65.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.66.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.66.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.66.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.66.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.66.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.66.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.66.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.66.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.66.mlp.up_proj.weight\n",
      "base_model.model.model.layers.66.mlp.down_proj.weight\n",
      "base_model.model.model.layers.66.input_layernorm.weight\n",
      "base_model.model.model.layers.66.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.67.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.67.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.67.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.67.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.67.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.67.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.67.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.67.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.67.mlp.up_proj.weight\n",
      "base_model.model.model.layers.67.mlp.down_proj.weight\n",
      "base_model.model.model.layers.67.input_layernorm.weight\n",
      "base_model.model.model.layers.67.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.68.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.68.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.68.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.68.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.68.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.68.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.68.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.68.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.68.mlp.up_proj.weight\n",
      "base_model.model.model.layers.68.mlp.down_proj.weight\n",
      "base_model.model.model.layers.68.input_layernorm.weight\n",
      "base_model.model.model.layers.68.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.69.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.69.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.69.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.69.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.69.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.69.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.69.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.69.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.69.mlp.up_proj.weight\n",
      "base_model.model.model.layers.69.mlp.down_proj.weight\n",
      "base_model.model.model.layers.69.input_layernorm.weight\n",
      "base_model.model.model.layers.69.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.70.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.70.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.70.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.70.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.70.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.70.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.70.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.70.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.70.mlp.up_proj.weight\n",
      "base_model.model.model.layers.70.mlp.down_proj.weight\n",
      "base_model.model.model.layers.70.input_layernorm.weight\n",
      "base_model.model.model.layers.70.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.71.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.71.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.71.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.71.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.71.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.71.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.71.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.71.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.71.mlp.up_proj.weight\n",
      "base_model.model.model.layers.71.mlp.down_proj.weight\n",
      "base_model.model.model.layers.71.input_layernorm.weight\n",
      "base_model.model.model.layers.71.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.72.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.72.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.72.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.72.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.72.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.72.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.72.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.72.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.72.mlp.up_proj.weight\n",
      "base_model.model.model.layers.72.mlp.down_proj.weight\n",
      "base_model.model.model.layers.72.input_layernorm.weight\n",
      "base_model.model.model.layers.72.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.73.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.73.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.73.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.73.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.73.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.73.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.73.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.73.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.73.mlp.up_proj.weight\n",
      "base_model.model.model.layers.73.mlp.down_proj.weight\n",
      "base_model.model.model.layers.73.input_layernorm.weight\n",
      "base_model.model.model.layers.73.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.74.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.74.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.74.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.74.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.74.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.74.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.74.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.74.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.74.mlp.up_proj.weight\n",
      "base_model.model.model.layers.74.mlp.down_proj.weight\n",
      "base_model.model.model.layers.74.input_layernorm.weight\n",
      "base_model.model.model.layers.74.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.75.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.75.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.75.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.75.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.75.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.75.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.75.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.75.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.75.mlp.up_proj.weight\n",
      "base_model.model.model.layers.75.mlp.down_proj.weight\n",
      "base_model.model.model.layers.75.input_layernorm.weight\n",
      "base_model.model.model.layers.75.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.76.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.76.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.76.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.76.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.76.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.76.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.76.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.76.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.76.mlp.up_proj.weight\n",
      "base_model.model.model.layers.76.mlp.down_proj.weight\n",
      "base_model.model.model.layers.76.input_layernorm.weight\n",
      "base_model.model.model.layers.76.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.77.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.77.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.77.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.77.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.77.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.77.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.77.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.77.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.77.mlp.up_proj.weight\n",
      "base_model.model.model.layers.77.mlp.down_proj.weight\n",
      "base_model.model.model.layers.77.input_layernorm.weight\n",
      "base_model.model.model.layers.77.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.78.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.78.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.78.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.78.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.78.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.78.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.78.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.78.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.78.mlp.up_proj.weight\n",
      "base_model.model.model.layers.78.mlp.down_proj.weight\n",
      "base_model.model.model.layers.78.input_layernorm.weight\n",
      "base_model.model.model.layers.78.post_attention_layernorm.weight\n",
      "base_model.model.model.layers.79.self_attn.q_proj.weight\n",
      "base_model.model.model.layers.79.self_attn.q_proj.bias\n",
      "base_model.model.model.layers.79.self_attn.k_proj.weight\n",
      "base_model.model.model.layers.79.self_attn.k_proj.bias\n",
      "base_model.model.model.layers.79.self_attn.v_proj.weight\n",
      "base_model.model.model.layers.79.self_attn.v_proj.bias\n",
      "base_model.model.model.layers.79.self_attn.o_proj.weight\n",
      "base_model.model.model.layers.79.mlp.gate_proj.weight\n",
      "base_model.model.model.layers.79.mlp.up_proj.weight\n",
      "base_model.model.model.layers.79.mlp.down_proj.weight\n",
      "base_model.model.model.layers.79.input_layernorm.weight\n",
      "base_model.model.model.layers.79.post_attention_layernorm.weight\n",
      "base_model.model.model.norm.weight\n",
      "base_model.model.score.original_module.weight\n",
      "base_model.model.score.modules_to_save.default.weight\n"
     ]
    }
   ],
   "source": [
    "#層の表示\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae85e702-1a16-4ee2-8aa7-73c2c10235bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_csv(\"../train.csv\")\n",
    "#ds = ds.select(torch.arange(100))  # We only use the first 100 data for demo purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19db02c7-dc53-4852-a7e4-d4cf81a85da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3-season skirt!</td>\n",
       "      <td>Adorable, well-made skirt! lined and very slim...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>Very cute</td>\n",
       "      <td>Love the asymmetrical hem. waist fit snugly as...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>Beautiful! fruns small for typical retailer si...</td>\n",
       "      <td>I love this skirt! i wasn't sure about the mix...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I was really pleased with this skirt. the ligh...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>Unique, pretty asymmetric skirt</td>\n",
       "      <td>I saw this skirt in retailer several months ag...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                                              Title  \\\n",
       "0            0   25                                    3-season skirt!   \n",
       "1            0   39                                          Very cute   \n",
       "2            0   42  Beautiful! fruns small for typical retailer si...   \n",
       "3            0   45                                                NaN   \n",
       "4            0   57                    Unique, pretty asymmetric skirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Adorable, well-made skirt! lined and very slim...       5                1   \n",
       "1  Love the asymmetrical hem. waist fit snugly as...       5                1   \n",
       "2  I love this skirt! i wasn't sure about the mix...       5                1   \n",
       "3  I was really pleased with this skirt. the ligh...       5                1   \n",
       "4  I saw this skirt in retailer several months ag...       5                1   \n",
       "\n",
       "   Positive Feedback Count  \n",
       "0                        4  \n",
       "1                        0  \n",
       "2                        5  \n",
       "3                        9  \n",
       "4                        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"../train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc3944fe-ed4c-41d2-9321-647704991bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Clothing ID', 'Age', 'Title', 'Review Text', 'Rating',\n",
       "       'Recommended IND', 'Positive Feedback Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41526c34-9c83-4097-b26f-e44d12505a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        Clothing_ID = [\"<Clothing ID>: \" + self.process_text(t) for t in batch[\"Clothing ID\"]]\n",
    "        Age = [\"\\n\\n<Age>: \" + self.process_text(t) for t in batch[\"Age\"]]  # \"AGe\"を\"Age\"に修正\n",
    "        Title = [\"\\n\\n<Title>: \" + self.process_text(t) for t in batch[\"Title\"]]\n",
    "        Review_Text = [\"\\n\\n<Review Text>: \" + self.process_text(t) for t in batch[\"Review Text\"]]\n",
    "        Positive_Feedback_Count = [\"\\n\\n<Positive Feedback Count>: \" + self.process_text(t) for t in batch[\"Positive Feedback Count\"]]\n",
    "        \n",
    "        texts = [c + a + t + r + p for c, a, t, r, p in zip(Clothing_ID, Age, Title, Review_Text, Positive_Feedback_Count)]\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)\n",
    "\n",
    "        labels = batch[\"Recommended IND\"]  # ラベルの処理を簡略化\n",
    "            \n",
    "        return {**tokenized, \"labels\": labels}\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text: Any) -> str:\n",
    "        if isinstance(text, str):\n",
    "            try:\n",
    "                return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "            except:\n",
    "                return str(text)\n",
    "        else:\n",
    "            return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0130cb0-b9f6-4812-b0a4-3e985daee133",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)\n",
    "ds = ds.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e4596dc-c986-43cb-b02d-db84e6abe5ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37336fb9-972b-4df1-830d-4cd0f62d52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Clothing ID>: 0\n",
      "\n",
      "<Age>: 25\n",
      "\n",
      "<Title>: 3-season skirt!\n",
      "\n",
      "<Review Text>: Adorable, well-made skirt! lined and very slimming. i had to size up b/c it runs a bit snug around the waist. however, it's worth it b/c this will match many long and short sleeve tops!\n",
      "\n",
      "<Positive Feedback Count>: 4\n"
     ]
    }
   ],
   "source": [
    "#debug\n",
    "print(tokenizer.decode(ds[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7d56006-17f1-4e01-9747-3de3622288bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    \n",
    "    # ソフトマックス関数を適用して確率に変換\n",
    "    probs = np.exp(preds) / np.sum(np.exp(preds), axis=1, keepdims=True)\n",
    "    \n",
    "    # 予測クラスを取得\n",
    "    pred_classes = np.argmax(probs, axis=1)\n",
    "    \n",
    "    # 正解率（Accuracy）を計算\n",
    "    acc = accuracy_score(y_true=labels, y_pred=pred_classes)\n",
    "    \n",
    "    # ROC AUC スコアを計算（マルチクラスの場合は'ovr'を使用）\n",
    "    num_classes = probs.shape[1]\n",
    "    if num_classes == 2:\n",
    "        # バイナリ分類の場合\n",
    "        auc = roc_auc_score(labels, probs[:, 1])\n",
    "    else:\n",
    "        # マルチクラス分類の場合\n",
    "        auc = roc_auc_score(labels, probs, multi_class='ovr', average='macro')\n",
    "    \n",
    "    return {\"acc\": acc, \"roc_auc\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c766dfe-858a-4f5c-947e-50b1c3dc954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\n",
    "    (\n",
    "        [i for i in range(len(ds)) if i % config.n_splits != fold_idx],\n",
    "        [i for i in range(len(ds)) if i % config.n_splits == fold_idx]\n",
    "    ) \n",
    "    for fold_idx in range(config.n_splits)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82ad8d9b-9675-4ed6-bfbb-7f4f540a508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 8:12:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.257942</td>\n",
       "      <td>0.933500</td>\n",
       "      <td>0.975560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.3791950275599957, metrics={'train_runtime': 29545.2763, 'train_samples_per_second': 0.271, 'train_steps_per_second': 0.068, 'total_flos': 3.3702726972063744e+17, 'train_loss': 0.3791950275599957, 'epoch': 1.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, eval_idx = folds[config.fold_idx]\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=ds.select(train_idx),#ds,ds.select(train_idx),\n",
    "    eval_dataset=ds.select(eval_idx),#ds.select(torch.arange(100)),#ds.select(eval_idx),\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773eb77f-d399-4516-b9ef-1dc5263ab6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
